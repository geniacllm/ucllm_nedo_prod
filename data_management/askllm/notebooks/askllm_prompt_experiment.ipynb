{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JupyterLabを松尾研プレ環境でセットアップしてAsk-LLMを実行\n",
    "\n",
    "## 重要なドキュメント\n",
    "\n",
    "以下2つの松尾研提供のドキュメントを必ず読む。もし今読んでいるドキュメントとの矛盾があれば、以下の2つのドキュメントの記述を優先する(特にサーバ利用ルールが流動的に変わるので常に最新の情報を確認)。\n",
    "\n",
    "- 松尾研GCPサーバ利用手順書（プレ環境）\n",
    "  - https://docs.google.com/document/d/1kJiRqUFSm6pMFoIX4hqx1CxAIa5MBSwC9DndzB6pxqE/edit?usp=sharing\n",
    "- 松尾研リポジトリのインフラ構築手順\n",
    "  - https://github.com/matsuolab/ucllm_nedo_prod/blob/main/infra/README.md\n",
    "\n",
    "## 初回のセットアップ手順\n",
    "\n",
    "### gcloud CLI のインストール\n",
    "\n",
    "ローカルマシンに gcloud CLI をインストール。\n",
    "\n",
    "- https://cloud.google.com/sdk/docs/install\n",
    "\n",
    "### sshでログインノードに接続\n",
    "\n",
    "ローカルマシンのターミナルから以下のコマンドを実行してログインノードに接続。\n",
    "\n",
    "```bash\n",
    "export ZONE=\"asia-southeast1-a\"\n",
    "export INSTANCE=\"mlpre-login-...\"            # ログインノードのインスタンス名\n",
    "export PROJECT=\"g...\"                        # GCPプロジェクト名\n",
    "```\n",
    "\n",
    "```bash\n",
    "gcloud compute ssh --zone $ZONE $INSTANCE --project $PROJECT\n",
    "```\n",
    "\n",
    "### 計算ノードにbashでログイン\n",
    "\n",
    "計算ノードにbashでログインする。\n",
    "\n",
    "```bash\n",
    "srun --partition g2 --nodes=1 --gpus-per-node=1 --time=03:00:00 --pty bash -i\n",
    "```\n",
    "\n",
    "`squeue` して計算ノードの名前 `mlpre-g2-ghpc-...` を確認。計算ノードのマシン名 `mlpre-g2-...` は後でsshポートフォワーディングで使うのでメモしておく。\n",
    "\n",
    "### 共有ディスクに実験用ディレクトリを作成\n",
    "\n",
    "共有ディスクに実験用ディレクトリを作成。ディレクトリの場所やパーミッションはチームのルールに従う。\n",
    "\n",
    "```bash\n",
    "mkdir -p /persistentshare/storage/team_.../...\n",
    "chmod 700 /persistentshare/storage/team_.../...\n",
    "```\n",
    "\n",
    "環境変数で実験用ディレクトリの場所を指定。以下を実行するとともに `~/.bashrc` の末尾に追加。\n",
    "\n",
    "```bash\n",
    "export EXP_HOME=\"/persistentshare/storage/team_.../...\"\n",
    "```\n",
    "\n",
    "### Python 実行環境の構築\n",
    "\n",
    "松尾研マニュアルの以下ページを参考に EXP_HOME 以下に Miniconda をインストール。\n",
    "\n",
    "- https://github.com/matsuolab/ucllm_nedo_prod/blob/main/infra/README.md#environment-preparation\n",
    "\n",
    "```bash\n",
    "mkdir -p $EXP_HOME/miniconda3\n",
    "cd $EXP_HOME/miniconda3\n",
    "\n",
    "wget https://repo.anaconda.com/miniconda/Miniconda3-py310_23.10.0-1-Linux-x86_64.sh\n",
    "bash Miniconda3-py310_23.10.0-1-Linux-x86_64.sh -h  # オプションを確認\n",
    "# -b オプションでライセンスに同意したことになることに注意\n",
    "bash Miniconda3-py310_23.10.0-1-Linux-x86_64.sh -b -u -p $EXP_HOME/miniconda3\n",
    "\n",
    "source $EXP_HOME/miniconda3/etc/profile.d/conda.sh\n",
    "\n",
    "which conda      # $EXP_HOME/miniconda3/condabin/conda\n",
    "conda --version  # conda 23.10.0\n",
    "```\n",
    "\n",
    "conda環境の作成。\n",
    "\n",
    "```bash\n",
    "conda create --name jupyter39 python=3.9\n",
    "# conda create --name jupyter310 python=3.10\n",
    "```\n",
    "\n",
    "conda環境をアクティベートする。\n",
    "\n",
    "```bash\n",
    "conda activate jupyter39\n",
    "# conda activate jupyter310\n",
    "```\n",
    "\n",
    "CUDAとPyTorchのインストール。\n",
    "\n",
    "```bash\n",
    "conda install nvidia/label/cuda-11.8.0::cuda-toolkit -y\n",
    "\n",
    "conda install pytorch==2.2.0 torchvision==0.17.0 torchaudio==2.2.0 pytorch-cuda=11.8 -c pytorch -c nvidia -y\n",
    "```\n",
    "\n",
    "JupyterLabのインストール。\n",
    "\n",
    "```bash\n",
    "conda install -c conda-forge jupyterlab -y\n",
    "which jupyter-lab  # $HOME/miniconda3/envs/py310/bin/jupyter-lab\n",
    "jupyter-lab --version  # 4.1.5\n",
    "```\n",
    "\n",
    "### JupyterLabの動作確認\n",
    "\n",
    "JupyterLabを手動で起動して動作確認する。\n",
    "\n",
    "```bash\n",
    "jupyter-lab --no-browser --port 8888 --ip $(hostname -i)\n",
    "```\n",
    "\n",
    "ログに `http://127.0.0.1:8888/lab?token=...` のような行が出るので、クリップボードにコピーしておく。\n",
    "\n",
    "**今作業しているターミナルとは別のローカルマシンのターミナル**から、以下のコマンドを実行してローカルマシンのポート8888を計算ノード`mlpre-g2-...`のポート8888にフォワードする。`--` 以降のオプションは通常のsshコマンドのオプション。計算ノード名は `squeue` で確認する。\n",
    "\n",
    "```bash\n",
    "export ZONE=\"asia-southeast1-a\"\n",
    "export INSTANCE=\"mlpre-login-...\"       # ログインノードのインスタンス名\n",
    "export PROJECT=\"g...\"                   # プロジェクト名\n",
    "export COMPUTE_INSTANCE=\"mlpre-g2-...\"  # 割り当てられた計算ノードのインスタンス名\n",
    "```\n",
    "\n",
    "```bash\n",
    "gcloud compute ssh --zone $ZONE $INSTANCE --project $PROJECT -- -L 8888:$COMPUTE_INSTANCE:8888\n",
    "```\n",
    "\n",
    "ローカルマシンのブラウザで `http://127.0.0.1:8888/lab?token=...` にアクセスして、`!nvidia-smi` などを実行して、結果が表示されれば計算ノード内でJupyterLabが起動していることが確認できる。\n",
    "\n",
    "確認できたら、JupyterLabをCtrl-cで止めて、計算ノードからログアウトして `squeue` でジョブが終了していることを確認。していなければ `scancel [job_id]` でキャンセルする。\n",
    "\n",
    "```bash\n",
    "# Ctrl-cでJupyterLabを止める\n",
    "exit  # 計算ノードからログアウト\n",
    "squeue  # ジョブが終了していることを確認。していなければ scancel [job_id] でキャンセル\n",
    "```\n",
    "\n",
    "### バッチファイルでJupyterLabを起動\n",
    "\n",
    "手動でJupyterLabを起動できることが確認出来たので、バッチファイルを作成してジョブとして実行出来るようにする。\n",
    "\n",
    "松尾研の手順書とマニュアルを参考にする。\n",
    "\n",
    "- https://docs.google.com/document/d/1kJiRqUFSm6pMFoIX4hqx1CxAIa5MBSwC9DndzB6pxqE/edit?usp=sharing\n",
    "- https://github.com/matsuolab/ucllm_nedo_prod/blob/main/infra/README.md#batch\n",
    "\n",
    "`jupyterlab.sh` というファイルを作成して以下の内容を書き込む。**手順書の注意事項を参照してルールの範囲内で設定する**。\n",
    "\n",
    "```bash\n",
    "#!/bin/bash\n",
    "\n",
    "#SBATCH --gpus-per-node=1\n",
    "#SBATCH --time=06:00:00\n",
    "#SBATCH --partition=g2\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --job-name=jupyterlab\n",
    "#SBATCH --output=jupyterlab.log\n",
    "\n",
    "source $EXP_HOME/miniconda3/etc/profile.d/conda.sh\n",
    "conda activate jupyter39\n",
    "# conda activate jupyter310\n",
    "\n",
    "jupyter-lab --no-browser --port 8888 --ip $(hostname -i)\n",
    "```\n",
    "\n",
    "`sbatch` でジョブを投入。\n",
    "\n",
    "```bash\n",
    "sbatch jupyterlab.sh\n",
    "```\n",
    "\n",
    "`squeue` でジョブを確認。\n",
    "\n",
    "```bash\n",
    "squeue\n",
    "```\n",
    "\n",
    "`tail -f` でログを確認する。\n",
    "\n",
    "```bash\n",
    "tail -f jupyterlab.log\n",
    "```\n",
    "\n",
    "ログに `http://127.0.0.1:8888/lab?token=...` のような行が出るので、クリップボードにコピーしておく。\n",
    "\n",
    "ポートフォワードの設定を前節の手順で行っておく。\n",
    "\n",
    "ローカルマシンのブラウザで `http://127.0.0.1:8888/lab?token=...` にアクセスして、`!nvidia-smi` などを実行して、結果が表示されれば計算ノード内でJupyterLabが起動していることが確認できる。\n",
    "\n",
    "JupyterLabでの作業が完了したら必ず `scancel [job_id]` でジョブをキャンセルする。\n",
    "\n",
    "```bash\n",
    "# Ctrl-c で tail -f を止める\n",
    "squeue  # job_id を確認\n",
    "scancel [job_id]  # ジョブをキャンセル\n",
    "squeue  # キャンセル出来たか確認\n",
    "```\n",
    "\n",
    "## 2回目以降の手順\n",
    "\n",
    "### sshでログインノードに接続\n",
    "\n",
    "ローカルマシンのターミナルから以下のコマンドを実行してログインノードに接続。\n",
    "\n",
    "```bash\n",
    "export ZONE=\"asia-southeast1-a\"\n",
    "export INSTANCE=\"mlpre-login-...\"            # ログインノードのインスタンス名\n",
    "export PROJECT=\"g...\"                        # GCPプロジェクト名\n",
    "```\n",
    "\n",
    "```bash\n",
    "gcloud compute ssh --zone $ZONE $INSTANCE --project $PROJECT\n",
    "```\n",
    "\n",
    "### 計算ノードでJupyterLabをバッチ起動\n",
    "\n",
    "`squeue` して、以前の自分のジョブが終了していることを確認。終了していなければ `scancel [job_id]` でキャンセルする。\n",
    "\n",
    "JupyterLabをバッチ起動する。\n",
    "\n",
    "```bash\n",
    "sbacth jupyterlab.sh\n",
    "tail -f jupyterlab.log\n",
    "```\n",
    "\n",
    "ログに `http://127.0.0.1:8888/lab?token=...` のような行が出るので、クリップボードにコピーしておく。\n",
    "\n",
    "**今作業しているターミナルとは別のローカルマシンのターミナル**から、以下のコマンドを実行してローカルマシンのポート8888を計算ノード`mlpre-g2-...`のポート8888にフォワードする。`--` 以降のオプションは通常のsshコマンドのオプション。計算ノード名は `squeue` で確認する。\n",
    "\n",
    "```bash\n",
    "export ZONE=\"asia-southeast1-a\"\n",
    "export INSTANCE=\"mlpre-login-...\"       # ログインノードのインスタンス名\n",
    "export PROJECT=\"g...\"                   # プロジェクト名\n",
    "export COMPUTE_INSTANCE=\"mlpre-g2-...\"  # 割り当てられた計算ノードのインスタンス名\n",
    "```\n",
    "\n",
    "```bash\n",
    "gcloud compute ssh --zone $ZONE $INSTANCE --project $PROJECT -- -L 8888:$COMPUTE_INSTANCE:8888\n",
    "```\n",
    "\n",
    "**実験が終わったら必ず `scancel [job_id]` でジョブをキャンセル**する。\n",
    "\n",
    "```bash\n",
    "# Ctrl-c で tail -f を止める\n",
    "squeue  # job_id を確認\n",
    "scancel [job_id]  # ジョブをキャンセル\n",
    "squeue  # キャンセル出来たか確認\n",
    "```\n",
    "\n",
    "### ローカルマシンのVSCodeから計算ノードのJupyterLabに接続\n",
    "\n",
    "ローカルマシンのVSCodeから以下手順で計算ノードのJupyterLabに接続する。計算ノードでのJupyterLabの起動とポートフォワードの設定は事前に行っておく。\n",
    "\n",
    "VSCodeの手順は以下の通り。\n",
    "\n",
    "- ノートブックを開いた状態で\n",
    "- `Command Palette...`\n",
    "- `Notebook: Select Notebook Kernel`\n",
    "- `Existing Jupiter Server...`\n",
    "- コピーしておいた `http://127.0.0.1:8888/lab?token=...` を入力\n",
    "- `Select Kernel` で `Python 3 (ipykernel)` を選択\n",
    "- `!nvidia-smi` などを実行してみて結果が表示されれば計算ノードのJupyterLabに接続できているはず"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ask-LLM の実行\n",
    "\n",
    "ここまでの設定は Ask-LLM とは関係なく一般的にJupyterLabを松尾研プレ環境で使うための設定。\n",
    "\n",
    "ここからは Ask-LLM を実行するための手順。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scoring the CulturaX dataset with Ask-LLM\n",
    "\n",
    "%pip install nano-askllm\n",
    "%pip install datasets sentencepiece accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from time import time\n",
    "\n",
    "from datasets import load_dataset\n",
    "from nano_askllm import AskLLM\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer #, BitsAndBytesConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you must define the environment variable EXP_HOME or replace it with the path to the directory where the model will be saved\n",
    "hf_cache_dir = os.path.join(os.environ[\"EXP_HOME\"], \".cache/huggingface/hub\")\n",
    "\n",
    "# I think the `RakutenAI-7B-chat` model tends to say \"no\" to any kind of question.\n",
    "# so I use the `RakutenAI-7B-instruct` model instead.\n",
    "model_id = \"Rakuten/RakutenAI-7B-instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, torch_dtype=\"auto\", device_map=\"auto\", cache_dir=hf_cache_dir)\n",
    "# quantization_config = BitsAndBytesConfig(load_in_4bit=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\",\n",
    "    cache_dir=hf_cache_dir,\n",
    "    # quantization_config=quantization_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\n",
    "    \"uonlp/CulturaX\",\n",
    "    \"ja\",\n",
    "    split=\"train\",\n",
    "    cache_dir=\"/persistentshare/storage/team_kumagai/datasets\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_prefix = \"###\\n\"\n",
    "prompt_template_postfix = \"\"\"\n",
    "###\n",
    "\n",
    "Does the previous paragraph demarcated within ### and ### contain informative signal for pre-training a large-language model? An informative datapoint should be well-formatted, contain some usable knowledge of the world, and strictly NOT have any harmful, racist, sexist, etc. content.\n",
    "\n",
    "OPTIONS: yes/no\n",
    "ANSWER:\"\"\"  # noqa: E501\n",
    "\n",
    "yes_tokens = [\"yes\", \"Yes\"]\n",
    "\n",
    "llm = AskLLM(\n",
    "    tokenizer,\n",
    "    model,\n",
    "    prompt_template_prefix=prompt_template_prefix,\n",
    "    prompt_template_postfix=prompt_template_postfix,\n",
    "    yes_tokens=yes_tokens,\n",
    "    # you can increase it up to 8192 for Mistral-7B-v0.1 based models\n",
    "    max_tokens=512,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can increase batch_size up to about 16 if max_tokens is 512\n",
    "# or 8 for 1024, 4 for 2048, 2 for 4096, 1 for 8192, etc.\n",
    "batch_size = 1\n",
    "num_ask = 10\n",
    "\n",
    "start_time = time()\n",
    "\n",
    "# TODO: rewrite using `map` of `dataset`.\n",
    "# https://huggingface.co/docs/datasets/process#map\n",
    "for i in range(num_ask):\n",
    "    datapoints = dataset[i * batch_size : (i + 1) * batch_size][\"text\"]\n",
    "    scores = llm.ask(datapoints)\n",
    "    for score, datapoint in zip(scores.tolist(), datapoints):\n",
    "        text = datapoint[:80].replace(\"\\n\", \"\\\\n\")\n",
    "        print(f\"{score:.4f}\\t{text}\")\n",
    "    del scores\n",
    "\n",
    "end_time = time()\n",
    "print(f\"{(end_time - start_time):.4f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
